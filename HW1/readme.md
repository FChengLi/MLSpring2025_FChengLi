# **作业总结报告**

## 1. 问题分析与初步尝试

### 1.1 全特征训练的过拟合问题

在项目初期，我尝试将全部 88 个特征直接输入模型进行训练。尽管训练过程中的损失（Loss）正常下降，但在验证集和最终榜单上的表现却不尽人理想。

* **现象**：训练集表现良好，但验证集/测试集表现差。
* **归因**：这是典型的 **过拟合 (Overfitting)** 症状。将所有特征（包括弱相关或高噪声特征）一同输入，导致模型学习到了训练集中的噪声和 случайные флуктуации，增加了模型的方差，使其泛化能力下降。

### 1.2 大模型与强正则化的欠拟合问题

为了对抗过拟合，我尝试构建了一个更复杂的模型结构（例如，增加网络深度/宽度）并引入了多种正则化技术，如残差结构 (Residual Connection)、LayerNorm、Dropout 以及带有较强权重衰减 (Weight Decay) 的 AdamW 优化器。

* **现象**：模型在训练集和验证集上表现都趋于“稳定但保守”，无法达到理想的性能。
* **归因**：这表现出 **欠拟合 (Underfitting)** 的倾向。虽然正则化手段抑制了过拟合，但可能由于强度过大，或与数据标准化共同作用，导致模型无法充分学习数据中的有效模式。特别是标准化过程，在抑制噪声的同时，也可能“顺手”削弱了主信号的强度。

## 2. 核心调参过程与发现

### 2.1 特征选择 (SelectKBest)

特征数量是影响模型性能最关键的因素。

* **问题**：直接使用全部 88 个特征会引入大量噪声，严重干扰模型学习。
* **探索**：我测试了不同的 `k` 值（即选择最相关的特征数量），对比了 `k=12, 16, 24, 32` 等情况。
* **结论**：实验证明，`k=16` 时模型表现最佳。过少（如 12）或过多（如 24, 32）的特征都会导致性能显著下降。这说明，**有效的特征压缩是成功的关键**。

### 2.2 优化器动量 (Momentum)

在确定了 `k=16` 的基础上，我进一步优化了 SGD 优化器的动量（Momentum）参数。

* **作用**：引入动量可以帮助优化器在梯度更新时保持方向性，加速收敛并跳出局部最优。
* **探索**：我从 0.7 开始尝试，逐步增加至 0.8, 0.85 和 0.9。
* **结论**：动量的加入显著提升了模型性能。其中，`momentum=0.85` 时效果最好，优于 0.7 和 0.8，而 0.9 的表现则与 0.7 相当。

### 2.3 验证集划分比例 (valid_ratio)

验证集的比例同样对模型的最终表现有细微但重要的影响。

* **探索**：我测试了不同的验证集划分比例，如 0.2, 0.15, 0.1 和 0.05。
* **结论**：较小的验证集比例似乎能带来更好的结果，`valid_ratio=0.05` 时的表现最佳。这可能是因为更小的验证集意味着更大的训练集，使得模型能够学习到更充分的数据模式。

## 3. 实验结果

以下是几次关键实验的提交结果对比，最佳成绩已加粗表示：

| 排名 | 模型设置 (Key Settings) | Private Score | Public Score | 备注 |
|---:|:------------------------------------------------|---:|---:|:---|
| 8 | **k=16 + momentum=0.85 + valid_ratio=0.05** | **0.86199** | **0.81159** | **最终最佳配置** |
| 7 | k=16 + momentum=0.85 + valid_ratio=0.2 | 0.86566 | 0.81854 | 验证集比例调整 |
| 6 | k=16 + momentum=0.7 | 0.88023 | 0.83498 | 引入动量 |
| 1 | k=16 | 0.98705 | 0.96827 | 仅使用特征选择 |
| 2 | layer = [24, 24] | 1.02188 | 0.99849 | 调整网络宽度 |
| 3 | k=12 | 1.10514 | 1.07651 | 特征数不足 |
| 4 | k=24 | 1.11734 | 1.09724 | 特征数过多 |
| 5 | k=32 | 1.87881 | 1.88481 | 特征数过多 |

## 4. 总结与反思

本次作业的核心经验是：**模型的复杂度和技术的堆砌并不总能带来性能的提升。**

1.  **特征工程至关重要**：最显著的性能提升来自于 `SelectKBest` 的特征选择。这表明，在信噪比较低的数据集上，首先进行有效的数据清洗和特征筛选，比直接上马复杂模型更为关键。
2.  **简单有效原则**：一个相对简单的模型，配合经过精心调试的关键超参数（如特征数 `k` 和优化器动量 `momentum`），其效果远胜于一个结构复杂但正则化过度或特征不佳的模型。
3.  **最终成绩**：我的模型最终在 Public Score 上达到了 **0.81159**，成功超越了 Strong Baseline (0.92619)，并非常接近 Boss Baseline (0.81456)，说明本次的调优方向是正确且有效的。

---